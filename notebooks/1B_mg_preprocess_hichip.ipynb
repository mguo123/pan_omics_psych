{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1B_mg_preprocess_hichip\n",
    "\n",
    "06/03/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pybedtools\n",
    "import sys, re\n",
    "import os,glob\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from collections import defaultdict,Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20260"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prom_bed = pybedtools.BedTool('../data/external/promoter_hg19_2000_500_sort.bed')\n",
    "prom_bed.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_chr=[str(x) for x in list(range(1,23))]+['X','Y']\n",
    "valid_chr_2 = ['chr'+x for x in valid_chr]\n",
    "valid_chr = valid_chr+valid_chr_2\n",
    "def read_bedpe_file(filepath,anchor_width=5000,valid_chr=valid_chr):\n",
    "    results = defaultdict(int)\n",
    "    with open(filepath) as f:\n",
    "    #     result_idx=0\n",
    "        for idx, line in enumerate(f.readlines()):\n",
    "            #DEBUG\n",
    "    #         if idx>100:\n",
    "    #             break\n",
    "            if (idx % 500000)==0:\n",
    "                print(idx, len(results))\n",
    "            chr_x, start_x , stop_x,  chr_y , start_y , stop_y , etc , count  = line.strip().split(' ')\n",
    "        \n",
    "            # filter validity\n",
    "            if chr_x not in valid_chr:\n",
    "                #print('chr_x',chr_x)\n",
    "                continue\n",
    "            if chr_y not in valid_chr:\n",
    "                #print('chr_y',chr_y)\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            #rounding to anchor width\n",
    "            if not chr_x.startswith('chr'):\n",
    "                chr_x = 'chr'+chr_x\n",
    "            start_x = round(int(start_x)/anchor_width)*anchor_width\n",
    "            stop_x = max(start_x+anchor_width,round(int(stop_x)/anchor_width)*anchor_width)\n",
    "            if not chr_y.startswith('chr'):\n",
    "                chr_y = 'chr'+chr_y\n",
    "            start_y = round(int(start_y)/anchor_width)*anchor_width\n",
    "            stop_y = max(start_y+anchor_width,round(int(stop_y)/anchor_width)*anchor_width)\n",
    "\n",
    "            #partitioning to anchor width (deal with large fragments)\n",
    "            anchors_x=[]\n",
    "            for x in range(start_x, stop_x,anchor_width):\n",
    "                anchors_x.append(chr_x+'_' + str(x) +\"_\"+str(x+anchor_width))\n",
    "            anchors_y=[]\n",
    "            for x in range(start_y, stop_y,anchor_width):\n",
    "                anchors_y.append(chr_y+'_' + str(x) +\"_\"+str(x+anchor_width))\n",
    "\n",
    "            for source in anchors_x:\n",
    "                for target in anchors_y:\n",
    "                    results[(source,target)] += int(count)\n",
    "#                     results[(target,source)] += int(count)\n",
    "\n",
    "    loop_df = pd.concat([pd.DataFrame(results.keys()),pd.DataFrame(results.values())],axis=1)\n",
    "    loop_df.columns=['source','target','count']\n",
    "    return loop_df\n",
    "\n",
    "\n",
    "def hichip_to_anchor(hichip_df, sample):\n",
    "    \"\"\"\n",
    "    hichip_df<DataFrame> from `hichip_to_df`\n",
    "    \"\"\"\n",
    "    anchors_list = sorted(set(hichip_df.source).union(set(hichip_df.target)))\n",
    "    anchors_df = pd.DataFrame({\"anchors\":anchors_list})\n",
    "    anchors_df_split = anchors_df.anchors.str.split('_', expand=True)\n",
    "    anchors_df_split.columns = ['chr', 'start', 'end']\n",
    "    anchors_df = pd.concat([anchors_df, anchors_df_split], axis=1)\n",
    "    anchors_df['sample']= sample\n",
    "    anchors_df = anchors_df[['chr','start','end','anchors','sample']]\n",
    "    return anchors_df\n",
    "\n",
    "\n",
    "def filter_through_tss(anchor_df, prom_bed):\n",
    "    anchor_bed = pybedtools.BedTool.from_dataframe(anchor_df).sort()\n",
    "    return anchor_bed.intersect(prom_bed, wa=True, wb=False, sorted=True).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "input_filepath = '../data/raw/hichip/'\n",
    "output_filepath = '../data/interim/merged/'\n",
    "extension='.bedpe'\n",
    "type_prefix=''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up file paths\n",
    "if not os.path.exists(output_filepath):\n",
    "    os.makedirs(output_filepath)\n",
    "\n",
    "loops_dir = os.path.join(output_filepath, 'loops')\n",
    "anchors_dir = os.path.join(output_filepath, 'anchors')\n",
    "anchors_bed_dir = os.path.join(output_filepath, 'anchors_bed')\n",
    "if not os.path.exists(loops_dir):\n",
    "    os.makedirs(loops_dir)\n",
    "    os.makedirs(anchors_dir)\n",
    "    os.makedirs(anchors_bed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging and csv... \n",
      "merging and csv... SL_D2\n",
      "../data/raw/hichip/SL_D2/SLNgn2-20.filt.intra.loop_counts.bedpe\n",
      "0 0\n",
      "500000 1770771\n",
      "1000000 3556018\n",
      "1500000 5298088\n",
      "2000000 7150031\n",
      "2500000 8975736\n",
      "3000000 11166873\n",
      "3500000 13180643\n",
      "4000000 14765495\n",
      "4500000 16204844\n",
      "5000000 17758280\n",
      "5500000 19683472\n",
      "6000000 21606650\n",
      "6500000 23898889\n",
      "7000000 25540922\n",
      "7500000 27546033\n",
      "8000000 29683305\n",
      "8500000 32137864\n",
      "9000000 34647062\n",
      "9500000 36816361\n",
      "10000000 39129203\n",
      "10500000 41232868\n",
      "11000000 43638499\n",
      "11500000 45707002\n",
      "12000000 47731925\n",
      "12500000 49771495\n",
      "13000000 51804079\n",
      "read loop_df (53032965, 3)\n",
      "read anchor_df (406093, 5)\n",
      "start (53032965, 3) (406093, 5)\n",
      "../data/raw/hichip/SL_D2/SLNgn2-21.filt.intra.loop_counts.bedpe\n",
      "0 0\n",
      "500000 1720545\n",
      "1000000 3489628\n",
      "1500000 5132450\n",
      "2000000 6840636\n",
      "2500000 8562141\n",
      "3000000 10633053\n",
      "3500000 12593272\n",
      "4000000 14129082\n",
      "4500000 15557478\n",
      "5000000 17036470\n",
      "5500000 18904301\n",
      "6000000 20533056\n",
      "6500000 22711662\n",
      "7000000 24428644\n",
      "7500000 26331949\n",
      "8000000 28341054\n",
      "8500000 30470319\n",
      "9000000 32839884\n",
      "9500000 35101286\n",
      "10000000 37107572\n",
      "10500000 39188680\n",
      "11000000 41267603\n",
      "11500000 43302187\n",
      "12000000 45368904\n",
      "12500000 47187165\n",
      "13000000 49048717\n",
      "read loop_df (50589958, 3)\n",
      "read anchor_df (400175, 5)\n",
      "merging\n",
      "merging done (80043168, 3) (473838, 5)\n",
      "end loop through tissue folder, now filtering\n",
      "filtering done SL_D2 (5324429, 3) (460761, 5)\n",
      "merging and csv... H9_D10\n",
      "../data/raw/hichip/H9_D10/H9D10-B1.filt.intra.loop_counts.bedpe\n",
      "0 0\n",
      "500000 623667\n",
      "1000000 1243434\n",
      "1500000 1868120\n",
      "2000000 2470384\n",
      "2500000 3097566\n",
      "3000000 3734702\n",
      "3500000 4371260\n",
      "4000000 4998056\n",
      "4500000 5632635\n",
      "5000000 6254875\n",
      "read loop_df (6525242, 3)\n",
      "read anchor_df (300727, 5)\n",
      "start (6525242, 3) (300727, 5)\n",
      "../data/raw/hichip/H9_D10/H9D10-B2.filt.intra.loop_counts.bedpe\n",
      "0 0\n",
      "500000 565258\n",
      "1000000 1131168\n",
      "read loop_df (1679263, 3)\n",
      "read anchor_df (236465, 5)\n",
      "merging\n",
      "merging done (7663374, 3) (349821, 5)\n",
      "end loop through tissue folder, now filtering\n",
      "filtering done H9_D10 (712533, 3) (230431, 5)\n",
      "merging and csv... H9_D28\n",
      "../data/raw/hichip/H9_D28/H9D28-B1.filt.intra.loop_counts.bedpe\n",
      "0 0\n",
      "500000 1924441\n",
      "1000000 3799203\n",
      "1500000 5864952\n",
      "read loop_df (7543116, 3)\n",
      "read anchor_df (429630, 5)\n",
      "start (7543116, 3) (429630, 5)\n",
      "../data/raw/hichip/H9_D28/H9D28-B2.filt.intra.loop_counts.bedpe\n",
      "0 0\n",
      "500000 1482020\n",
      "1000000 2990974\n",
      "1500000 4484022\n",
      "2000000 6118829\n",
      "2500000 7757059\n",
      "read loop_df (9176738, 3)\n",
      "read anchor_df (420967, 5)\n",
      "merging\n",
      "merging done (15609231, 3) (512803, 5)\n",
      "end loop through tissue folder, now filtering\n",
      "filtering done H9_D28 (1256959, 3) (345113, 5)\n",
      "merging and csv... SLC_D2\n",
      "../data/raw/hichip/SLC_D2/SLCNgn2-20.filt.intra.loop_counts.bedpe\n",
      "0 0\n",
      "500000 1488277\n",
      "1000000 2873423\n",
      "1500000 4290610\n",
      "2000000 5718156\n",
      "2500000 7274081\n",
      "3000000 9022524\n",
      "3500000 10819363\n",
      "4000000 12192676\n",
      "4500000 13356746\n",
      "5000000 14599009\n",
      "5500000 16258641\n",
      "6000000 17603651\n",
      "6500000 19384491\n",
      "7000000 21234431\n",
      "7500000 22707083\n",
      "8000000 24424769\n",
      "8500000 26053652\n",
      "9000000 28148411\n",
      "9500000 30019340\n",
      "10000000 31669380\n",
      "10500000 33593105\n",
      "11000000 35215476\n",
      "11500000 37030194\n",
      "12000000 38793512\n",
      "12500000 40516852\n",
      "13000000 42084610\n",
      "13500000 43707264\n",
      "read loop_df (43884017, 3)\n",
      "read anchor_df (389168, 5)\n",
      "start (43884017, 3) (389168, 5)\n",
      "../data/raw/hichip/SLC_D2/SLCNgn2-21.filt.intra.loop_counts.bedpe\n",
      "0 0\n",
      "500000 1350425\n",
      "1000000 2616929\n",
      "1500000 3961960\n",
      "2000000 5247375\n",
      "2500000 6827260\n",
      "3000000 8357108\n",
      "3500000 9496141\n",
      "4000000 10650992\n",
      "4500000 12114997\n",
      "5000000 13354517\n",
      "5500000 15080176\n",
      "6000000 16391563\n",
      "6500000 17903557\n",
      "7000000 19434003\n",
      "7500000 21218109\n",
      "8000000 22834234\n",
      "8500000 24415419\n",
      "9000000 25851148\n",
      "9500000 27463631\n",
      "10000000 29006853\n",
      "10500000 30404142\n",
      "11000000 31839906\n",
      "read loop_df (32535208, 3)\n",
      "read anchor_df (381355, 5)\n",
      "merging\n",
      "merging done (62195422, 3) (461359, 5)\n",
      "end loop through tissue folder, now filtering\n",
      "filtering done SLC_D2 (4282155, 3) (438625, 5)\n",
      "merging and csv... H9_D2\n",
      "../data/raw/hichip/H9_D2/H9Ngn2-13.filt.intra.loop_counts.bedpe\n",
      "0 0\n",
      "500000 1760070\n",
      "1000000 3586542\n",
      "1500000 5291421\n",
      "2000000 7335209\n",
      "2500000 8941340\n",
      "3000000 10595327\n",
      "3500000 12615705\n",
      "4000000 15027232\n",
      "4500000 16554195\n",
      "5000000 17873282\n",
      "5500000 19284412\n",
      "6000000 20577951\n",
      "6500000 22535693\n",
      "7000000 24148701\n",
      "7500000 25925148\n",
      "8000000 28094560\n",
      "8500000 29880431\n",
      "9000000 31645049\n",
      "9500000 33806740\n",
      "10000000 35694213\n",
      "10500000 38607125\n",
      "11000000 41154298\n",
      "11500000 43425787\n",
      "12000000 45737809\n",
      "12500000 47935216\n",
      "13000000 50172870\n",
      "13500000 52182358\n",
      "14000000 54287913\n",
      "14500000 56292072\n",
      "15000000 58090693\n",
      "15500000 60283724\n",
      "read loop_df (61079461, 3)\n",
      "read anchor_df (400852, 5)\n",
      "start (61079461, 3) (400852, 5)\n",
      "../data/raw/hichip/H9_D2/H9Ngn2-14.filt.intra.loop_counts.bedpe\n",
      "0 0\n",
      "500000 1485762\n",
      "1000000 3277202\n",
      "1500000 4862773\n",
      "2000000 6213253\n",
      "2500000 7936739\n",
      "3000000 9537546\n",
      "3500000 11340825\n",
      "4000000 13229295\n",
      "4500000 15358572\n",
      "5000000 16807597\n",
      "5500000 18098559\n",
      "6000000 19463416\n",
      "6500000 20723914\n",
      "7000000 22044815\n",
      "7500000 23996296\n",
      "8000000 25254966\n",
      "8500000 27106369\n",
      "9000000 29290963\n",
      "9500000 30885541\n",
      "10000000 32501319\n",
      "10500000 34340945\n",
      "11000000 36614240\n",
      "11500000 38640896\n",
      "12000000 41168811\n",
      "12500000 43374658\n",
      "13000000 45244033\n",
      "13500000 47546573\n",
      "14000000 49572079\n",
      "14500000 51641828\n",
      "15000000 53481348\n",
      "15500000 55474881\n",
      "16000000 57354177\n",
      "16500000 59012155\n",
      "17000000 60984770\n",
      "17500000 62842039\n",
      "read loop_df (62847447, 3)\n",
      "read anchor_df (398958, 5)\n",
      "merging\n",
      "merging done (93359900, 3) (470106, 5)\n",
      "end loop through tissue folder, now filtering\n",
      "filtering done H9_D2 (6720106, 3) (461684, 5)\n",
      "merging and csv... SL_D0\n",
      "../data/raw/hichip/SL_D0/SL-B1.filt.intra.loop_counts.bedpe\n",
      "0 0\n",
      "500000 638447\n",
      "1000000 1271274\n",
      "1500000 1923532\n",
      "2000000 2553577\n",
      "2500000 3206099\n",
      "3000000 3855693\n",
      "3500000 4504955\n",
      "4000000 5153880\n",
      "4500000 5800140\n",
      "read loop_df (6381814, 3)\n",
      "read anchor_df (291619, 5)\n",
      "start (6381814, 3) (291619, 5)\n",
      "../data/raw/hichip/SL_D0/SL-B2.filt.intra.loop_counts.bedpe\n",
      "0 0\n",
      "500000 695715\n",
      "1000000 1371094\n",
      "1500000 2072872\n",
      "2000000 2761913\n",
      "2500000 3417416\n",
      "3000000 4086491\n",
      "3500000 4816357\n",
      "4000000 5529776\n",
      "4500000 6245253\n",
      "5000000 6953661\n",
      "5500000 7668634\n",
      "6000000 8378033\n",
      "6500000 9070146\n",
      "read loop_df (9369871, 3)\n",
      "read anchor_df (323912, 5)\n",
      "merging\n",
      "merging done (14056212, 3) (387022, 5)\n",
      "end loop through tissue folder, now filtering\n",
      "filtering done SL_D0 (1187599, 3) (297076, 5)\n",
      "merging and csv... Astrocytes\n",
      "../data/raw/hichip/Astrocytes/Astro_B1.filt.intra.loop_counts.bedpe\n",
      "0 0\n",
      "500000 731952\n",
      "1000000 1477686\n",
      "1500000 2215873\n",
      "2000000 2966465\n",
      "2500000 3749185\n",
      "3000000 4489998\n",
      "3500000 5201160\n",
      "4000000 5918368\n",
      "4500000 6644134\n",
      "5000000 7409971\n",
      "5500000 8169142\n",
      "6000000 8925090\n",
      "6500000 9699731\n",
      "7000000 10505723\n",
      "7500000 11306164\n",
      "8000000 12086056\n",
      "8500000 12869807\n",
      "9000000 13624972\n",
      "9500000 14396927\n",
      "10000000 15136008\n",
      "read loop_df (15801783, 3)\n",
      "read anchor_df (330680, 5)\n",
      "start (15801783, 3) (330680, 5)\n",
      "../data/raw/hichip/Astrocytes/Astro_B2.filt.intra.loop_counts.bedpe\n",
      "0 0\n",
      "500000 732779\n",
      "1000000 1445165\n",
      "1500000 2156778\n",
      "2000000 2886032\n",
      "2500000 3576971\n",
      "3000000 4280205\n",
      "3500000 4996439\n",
      "4000000 5755922\n",
      "4500000 6501014\n",
      "5000000 7221218\n",
      "5500000 7967978\n",
      "6000000 8686786\n",
      "6500000 9407904\n",
      "7000000 10122018\n",
      "read loop_df (10265883, 3)\n",
      "read anchor_df (240128, 5)\n",
      "merging\n",
      "merging done (22302849, 3) (374392, 5)\n",
      "end loop through tissue folder, now filtering\n",
      "filtering done Astrocytes (1839205, 3) (322550, 5)\n",
      "merging and csv... H9_D0\n",
      "../data/raw/hichip/H9_D0/H9-B1.filt.intra.loop_counts.bedpe\n",
      "0 0\n",
      "500000 643509\n",
      "1000000 1279448\n",
      "1500000 1918144\n",
      "2000000 2569172\n",
      "2500000 3199667\n",
      "3000000 3842176\n",
      "3500000 4478415\n",
      "4000000 5136948\n",
      "4500000 5797284\n",
      "5000000 6459483\n",
      "5500000 7118788\n",
      "6000000 7778616\n",
      "6500000 8434531\n",
      "7000000 9099686\n",
      "read loop_df (9549601, 3)\n",
      "read anchor_df (317056, 5)\n",
      "start (9549601, 3) (317056, 5)\n",
      "../data/raw/hichip/H9_D0/H9-B2.filt.intra.loop_counts.bedpe\n",
      "0 0\n",
      "500000 636923\n",
      "1000000 1262260\n",
      "1500000 1901666\n",
      "2000000 2527872\n",
      "2500000 3143962\n",
      "3000000 3777458\n",
      "3500000 4421111\n",
      "4000000 5070309\n",
      "4500000 5723512\n",
      "5000000 6375572\n",
      "5500000 7018506\n",
      "6000000 7661087\n",
      "read loop_df (8264745, 3)\n",
      "read anchor_df (319794, 5)\n",
      "merging\n",
      "merging done (15535473, 3) (388258, 5)\n",
      "end loop through tissue folder, now filtering\n",
      "filtering done H9_D0 (1318716, 3) (306851, 5)\n",
      "merging and csv... SLC_D0\n",
      "../data/raw/hichip/SLC_D0/SLC-B1.filt.intra.loop_counts.bedpe\n",
      "0 0\n",
      "500000 700857\n",
      "1000000 1394414\n",
      "1500000 2086126\n",
      "2000000 2773479\n",
      "2500000 3461160\n",
      "3000000 4149015\n",
      "3500000 4809889\n",
      "4000000 5488799\n",
      "4500000 6190153\n",
      "5000000 6911703\n",
      "5500000 7626421\n",
      "6000000 8324756\n",
      "6500000 9031693\n",
      "7000000 9721424\n",
      "7500000 10421210\n",
      "8000000 11120318\n",
      "8500000 11807742\n",
      "read loop_df (12168410, 3)\n",
      "read anchor_df (312072, 5)\n",
      "start (12168410, 3) (312072, 5)\n",
      "../data/raw/hichip/SLC_D0/SLC-B2.filt.intra.loop_counts.bedpe\n",
      "0 0\n",
      "500000 796747\n",
      "1000000 1567015\n",
      "1500000 2325711\n",
      "2000000 3066740\n",
      "2500000 3854964\n",
      "3000000 4655620\n",
      "3500000 5431858\n",
      "4000000 6221339\n",
      "4500000 6983165\n",
      "5000000 7715013\n",
      "5500000 8517966\n",
      "6000000 9270111\n",
      "6500000 10067556\n",
      "7000000 10909467\n",
      "7500000 11700381\n",
      "8000000 12520690\n",
      "8500000 13312294\n",
      "9000000 14110034\n",
      "9500000 14903445\n",
      "10000000 15679753\n",
      "10500000 16497807\n",
      "11000000 17275698\n",
      "11500000 18070253\n",
      "12000000 18864143\n",
      "12500000 19658768\n",
      "13000000 20437614\n",
      "read loop_df (20602253, 3)\n",
      "read anchor_df (339248, 5)\n",
      "merging\n",
      "merging done (27736046, 3) (393827, 5)\n",
      "end loop through tissue folder, now filtering\n",
      "filtering done SLC_D0 (2659082, 3) (348166, 5)\n",
      "CPU times: user 38min 6s, sys: 1min 34s, total: 39min 40s\n",
      "Wall time: 38min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tissue_loop_dict = {}\n",
    "for subdir, dirs, files in os.walk(input_filepath):\n",
    "    tissue = os.path.basename(subdir)\n",
    "    file_idx = 0\n",
    "    print('merging and csv...', tissue)\n",
    "    \n",
    "    \n",
    "#     #DEBUG\n",
    "#     if tissue!='H9_D28':\n",
    "#         continue\n",
    "#     merged_loop_df = pd.DataFrame()\n",
    "#     merged_anchor_df = pd.DataFrame()\n",
    "\n",
    "    # loop through tissue folder\n",
    "    for filename in sorted(files):\n",
    "\n",
    "        input_filepath = os.path.join(subdir, filename )# bedpe file\n",
    "        output_filepath_tissue = subdir\n",
    "\n",
    "        if filename.endswith(extension) :\n",
    "            print(input_filepath)\n",
    "            loop_df = read_bedpe_file(input_filepath)\n",
    "            print('read loop_df',loop_df.shape)\n",
    "            anchors_df = hichip_to_anchor(loop_df,tissue)\n",
    "            print('read anchor_df',anchors_df.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "            if file_idx==0:\n",
    "                merged_loop_df = loop_df\n",
    "                merged_anchor_df = anchors_df\n",
    "                file_idx+=1\n",
    "                print('start',merged_loop_df.shape, merged_anchor_df.shape)\n",
    "#                 merged_anchor_df = anchors_df\n",
    "            else:\n",
    "                print('merging')\n",
    "                merged_loop_df = pd.concat([merged_loop_df, loop_df],ignore_index=True)\n",
    "                merged_loop_df = merged_loop_df.groupby(['source', 'target']).sum()\n",
    "                merged_loop_df.reset_index(inplace=True)\n",
    "                \n",
    "                merged_anchor_df = pd.concat([merged_anchor_df, anchors_df],ignore_index=True)\n",
    "                merged_anchor_df.drop_duplicates(subset=['chr','start', 'end'],inplace=True)\n",
    "                merged_anchor_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "                file_idx+=1\n",
    "                print('merging done',merged_loop_df.shape,merged_anchor_df.shape)\n",
    "\n",
    "\n",
    "    \n",
    "    # end loop through tissue folder\n",
    "    if file_idx>0:\n",
    "        print('end loop through tissue folder, now filtering')\n",
    "        merged_anchor_df_P = filter_through_tss(merged_anchor_df,prom_bed)\n",
    "        merged_anchor_df_P.columns = ['chr','start','end','anchors','sample']\n",
    "        anchors_P = merged_anchor_df_P.anchors.unique()\n",
    "        merged_loop_df['source_P'] = merged_loop_df.source.isin(anchors_P)\n",
    "        merged_loop_df['target_P'] = merged_loop_df.target.isin(anchors_P)\n",
    "        merged_loop_df['loop_P'] = merged_loop_df['source_P']  | merged_loop_df['target_P']\n",
    "        merged_loop_df = merged_loop_df[merged_loop_df.loop_P][['source','target','count']]\n",
    "        \n",
    "        merged_anchor_df= hichip_to_anchor(merged_loop_df,tissue)\n",
    "        print('filtering done',tissue, merged_loop_df.shape,merged_anchor_df.shape)\n",
    "\n",
    "\n",
    "        if merged_loop_df.shape[0]>0:\n",
    "            merged_loop_df.to_csv(os.path.join(loops_dir, tissue+type_prefix+'.loops.csv'))\n",
    "            merged_anchor_df.to_csv(os.path.join(anchors_dir, tissue+type_prefix+'.anchors.csv'))\n",
    "            merged_anchor_df = merged_anchor_df[['chr','start','end', 'anchors']]\n",
    "            merged_anchor_df.to_csv(os.path.join(anchors_bed_dir, tissue+type_prefix+'.anchors.bed'),sep='\\t', index=False, header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# washu tract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0:\n",
    "read over bed_longrange_formatting.py \n",
    "\n",
    "longrange\n",
    "The longrange track is a bed format-like file type. Each row contains columns from left to right: chromosome, start position (0-based), and end position (not included), interaction target in this format chr2:333-444,55. As an example, interval “chr1:111-222” interacts with interval “chr2:333-444” on a score of 55, we will use following two lines to represent this interaction:\n",
    "```\n",
    "chr1    111 222  chr2:333-444,55\n",
    "chr2    333 444  chr1:111-222,55\n",
    "```\n",
    "Important:\n",
    "- Be sure to make TWO records for a pair of interacting loci, one record for each locus.\n",
    "- check the bed files to see if 'chr' is a prefix,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: make longrange files\n",
    "- longrange format (see above)\n",
    "- sort bed file\n",
    "- save sorted bed file\n",
    "- bgzip file\n",
    "- tabix to create index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '../data/processed/washu/hichip'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SL_D2 ../data/interim/merged/loops/SL_D2.loops.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mguo123/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Astrocytes ../data/interim/merged/loops/Astrocytes.loops.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mguo123/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLC_D2 ../data/interim/merged/loops/SLC_D2.loops.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mguo123/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H9_D0 ../data/interim/merged/loops/H9_D0.loops.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mguo123/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SL_D0 ../data/interim/merged/loops/SL_D0.loops.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mguo123/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLC_D0 ../data/interim/merged/loops/SLC_D0.loops.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mguo123/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H9_D10 ../data/interim/merged/loops/H9_D10.loops.csv\n",
      "H9_D2 ../data/interim/merged/loops/H9_D2.loops.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mguo123/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H9_D28 ../data/interim/merged/loops/H9_D28.loops.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mguo123/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "longrange_dir = '../data/'\n",
    "for loop_file in glob.glob('../data/interim/merged/loops/*'):\n",
    "    # read in looping file and convert to longrange format\n",
    "    tissue = os.path.basename(loop_file).split('.')[0]\n",
    "    print(tissue, loop_file)\n",
    "    loop_df = pd.read_csv(loop_file, index_col=0)\n",
    "    loop_df_rev = loop_df.copy()\n",
    "    loop_df_rev = loop_df_rev[['target','source','count']]\n",
    "    loop_df_rev.columns = ['source','target','count']\n",
    "    loop_df_bi = pd.concat([loop_df, loop_df_rev],axis=0)\n",
    "    loop_df_bi[['chr','start','end']] = loop_df_bi.source.str.split('_',expand=True)\n",
    "    loop_df_bi[['chr2','start2','end2']] = loop_df_bi.target.str.split('_',expand=True)\n",
    "    loop_df_bi['target'] = loop_df_bi.chr2 + ':' + loop_df_bi.start2 + '-' + loop_df_bi.end2 + ',' + loop_df_bi['count'].map(str)\n",
    "    loop_df_bi = loop_df_bi[['chr','start','end','target']]\n",
    "    \n",
    "    # make bed file, sort, and save\n",
    "    loop_bed = pybedtools.BedTool.from_dataframe(loop_df_bi).sort()\n",
    "    output_filepath = os.path.join(save_dir, tissue+'_longrange.bed')\n",
    "    loop_bed.saveas(output_filepath)\n",
    "    \n",
    "    # bgzip bedfile\n",
    "    subprocess.Popen(['bgzip', output_filepath])\n",
    "    output_filepath_bzip = output_filepath+'.gz'\n",
    "    \n",
    "    # tabix create index\n",
    "    subprocess.Popen(['tabix', '-p', 'bed', output_filepath_bzip])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: make hub.config.json\n",
    "\n",
    "keep in same folder\n",
    "\n",
    "```\n",
    "[\n",
    "  {\n",
    "    \"filename\": \"H9_D0_longrange.bed.gz\",\n",
    "    \"type\":\"longrange\",\n",
    "    \"name\": \"H9_D0\",\n",
    "    \"label\":\"H9_D0\",\n",
    "    \"options\":{\n",
    "     \"color\":\"#8D4ECC\",\n",
    "     \"color2\":\"#004080\",\n",
    "     \"displayMode\":\"arc\",\n",
    "     \"label\":\"H9_D0\",\n",
    "     \"scoreMax\":40,\n",
    "     \"scoreMin\":10,\n",
    "     \"scoreScale\":\"fixed\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"filename\": \"H9_D2_longrange.bed.gz\",\n",
    "    \"type\":\"longrange\",\n",
    "    \"name\": \"H9_D2\",\n",
    "    \"label\":\"H9_D2\",\n",
    "    \"options\":{\n",
    "     \"color\":\"#8D4ECC\",\n",
    "     \"color2\":\"#004080\",\n",
    "     \"displayMode\":\"arc\",\n",
    "     \"label\":\"H9_D2\",\n",
    "     \"scoreMax\":40,\n",
    "     \"scoreMin\":10,\n",
    "     \"scoreScale\":\"fixed\"\n",
    "    }\n",
    "  },\n",
    "    {\n",
    "    \"filename\": \"H9_D4_longrange.bed.gz\",\n",
    "    \"type\":\"longrange\",\n",
    "    \"name\": \"H9_D4\",\n",
    "    \"label\":\"H9_D4\",\n",
    "    \"options\":{\n",
    "     \"color\":\"#8D4ECC\",\n",
    "     \"color2\":\"#004080\",\n",
    "     \"displayMode\":\"arc\",\n",
    "     \"label\":\"H9_D4\",\n",
    "     \"scoreMax\":40,\n",
    "     \"scoreMin\":10,\n",
    "     \"scoreScale\":\"fixed\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"filename\": \"H9_D10_longrange.bed.gz\",\n",
    "    \"type\":\"longrange\",\n",
    "    \"name\": \"H9_D10\",\n",
    "    \"label\":\"H9_D10\",\n",
    "    \"options\":{\n",
    "     \"color\":\"#8D4ECC\",\n",
    "     \"color2\":\"#004080\",\n",
    "     \"displayMode\":\"arc\",\n",
    "     \"label\":\"H9_D10\",\n",
    "     \"scoreMax\":40,\n",
    "     \"scoreMin\":10,\n",
    "     \"scoreScale\":\"fixed\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"filename\": \"H9_D28_longrange.bed.gz\",\n",
    "    \"type\":\"longrange\",\n",
    "    \"name\": \"H9_D28\",\n",
    "    \"label\":\"H9_D28\",\n",
    "    \"options\":{\n",
    "     \"color\":\"#8D4ECC\",\n",
    "     \"color2\":\"#004080\",\n",
    "     \"displayMode\":\"arc\",\n",
    "     \"label\":\"H9_D28\",\n",
    "     \"scoreMax\":40,\n",
    "     \"scoreMin\":10,\n",
    "     \"scoreScale\":\"fixed\"\n",
    "    }\n",
    "  },\n",
    "    {\n",
    "    \"filename\": \"SL_D0_longrange.bed.gz\",\n",
    "    \"type\":\"longrange\",\n",
    "    \"name\": \"SL_D0\",\n",
    "    \"label\":\"SL_D0\",\n",
    "    \"options\":{\n",
    "     \"color\":\"#8D4ECC\",\n",
    "     \"color2\":\"#004080\",\n",
    "     \"displayMode\":\"arc\",\n",
    "     \"label\":\"SL_D0\",\n",
    "     \"scoreMax\":40,\n",
    "     \"scoreMin\":10,\n",
    "     \"scoreScale\":\"fixed\"\n",
    "    }\n",
    "  },\n",
    "      {\n",
    "        \"filename\": \"SL_D2_longrange.bed.gz\",\n",
    "      \t\"type\":\"longrange\",\n",
    "        \"name\": \"SL_D2\",\n",
    "     \t\"label\":\"SL_D2\",\n",
    "      \"options\":{\n",
    "         \"color\":\"#8D4ECC\",\n",
    "         \"color2\":\"#004080\",\n",
    "         \"displayMode\":\"arc\",\n",
    "         \"label\":\"SL_D2\",\n",
    "         \"scoreMax\":40,\n",
    "         \"scoreMin\":10,\n",
    "         \"scoreScale\":\"fixed\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"filename\": \"SLC_D0_longrange.bed.gz\",\n",
    "      \"type\":\"longrange\",\n",
    "      \"name\": \"SLC_D0\",\n",
    "      \"label\":\"SLC_D0\",\n",
    "      \"options\":{\n",
    "       \"color\":\"#8D4ECC\",\n",
    "       \"color2\":\"#004080\",\n",
    "       \"displayMode\":\"arc\",\n",
    "       \"label\":\"SLC_D0\",\n",
    "       \"scoreMax\":40,\n",
    "       \"scoreMin\":10,\n",
    "       \"scoreScale\":\"fixed\"\n",
    "      }\n",
    "    },\n",
    "      {\n",
    "        \"filename\": \"SLC_D2_longrange.bed.gz\",\n",
    "      \t\"type\":\"longrange\",\n",
    "        \"name\": \"SLC_D2\",\n",
    "     \t\"label\":\"SLC_D2\",\n",
    "      \"options\":{\n",
    "         \"color\":\"#8D4ECC\",\n",
    "         \"color2\":\"#004080\",\n",
    "         \"displayMode\":\"arc\",\n",
    "         \"label\":\"SLC_D2\",\n",
    "         \"scoreMax\":40,\n",
    "         \"scoreMin\":10,\n",
    "         \"scoreScale\":\"fixed\"\n",
    "      }\n",
    "    }\n",
    "\n",
    "]\n",
    "      }\n",
    "    },\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longrange (thres)\n",
    "- and normalize\n",
    "take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '../data/processed/washu/hichip_thres_adjust'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRES=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_file = '../data/interim/merged/loops/H9_D0.loops.csv'\n",
    "loop_df = pd.read_csv(loop_file, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<subprocess.Popen at 0x7ffd60aa5850>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.Popen(['tabix', '-p', 'bed', '../data/processed/washu/hichip/SLC_D2_longrange.bed.gz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SL_D2 ../data/interim/merged/loops/SL_D2.loops.csv (260004, 3) 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mguo123/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Astrocytes ../data/interim/merged/loops/Astrocytes.loops.csv (86821, 3) 13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mguo123/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLC_D2 ../data/interim/merged/loops/SLC_D2.loops.csv (205409, 3) 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mguo123/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H9_D0 ../data/interim/merged/loops/H9_D0.loops.csv (64452, 3) 6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mguo123/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SL_D0 ../data/interim/merged/loops/SL_D0.loops.csv (55307, 3) 6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mguo123/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLC_D0 ../data/interim/merged/loops/SLC_D0.loops.csv (120695, 3) 11.0\n",
      "H9_D10 ../data/interim/merged/loops/H9_D10.loops.csv (34846, 3) 5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mguo123/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H9_D2 ../data/interim/merged/loops/H9_D2.loops.csv (333897, 3) 30.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mguo123/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H9_D28 ../data/interim/merged/loops/H9_D28.loops.csv (45081, 3) 4.0\n",
      "CPU times: user 57.2 s, sys: 2.87 s, total: 1min\n",
      "Wall time: 44.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "longrange_dir = '../data/'\n",
    "for loop_file in glob.glob('../data/interim/merged/loops/*'):\n",
    "    # read in looping file and convert to longrange format\n",
    "    tissue = os.path.basename(loop_file).split('.')[0]\n",
    "    loop_df = pd.read_csv(loop_file, index_col=0)\n",
    "    thres = np.percentile(loop_df['count'],95)#.describe()#.iloc\n",
    "    loop_df = loop_df[loop_df['count']>thres]\n",
    "    print(tissue, loop_file,loop_df.shape, thres)\n",
    "    loop_df_rev = loop_df.copy()\n",
    "    loop_df_rev = loop_df_rev[['target','source','count']]\n",
    "    loop_df_rev.columns = ['source','target','count']\n",
    "    loop_df_bi = pd.concat([loop_df, loop_df_rev],axis=0)\n",
    "    loop_df_bi[['chr','start','end']] = loop_df_bi.source.str.split('_',expand=True)\n",
    "    loop_df_bi[['chr2','start2','end2']] = loop_df_bi.target.str.split('_',expand=True)\n",
    "    loop_df_bi['target'] = loop_df_bi.chr2 + ':' + loop_df_bi.start2 + '-' + loop_df_bi.end2 + ',' + loop_df_bi['count'].map(str)\n",
    "    loop_df_bi = loop_df_bi[['chr','start','end','target']]\n",
    "    \n",
    "    # make bed file, sort, and save\n",
    "    loop_bed = pybedtools.BedTool.from_dataframe(loop_df_bi).sort()\n",
    "    output_filepath = os.path.join(save_dir, tissue+'_longrange.bed')\n",
    "    loop_bed.saveas(output_filepath)\n",
    "    \n",
    "    # bgzip bedfile\n",
    "    subprocess.Popen(['bgzip', output_filepath])\n",
    "    output_filepath_bzip = output_filepath+'.gz'\n",
    "    \n",
    "    # tabix create index\n",
    "    subprocess.Popen(['tabix', '-p', 'bed', output_filepath_bzip])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tissue_loop_dict = {}\n",
    "for subdir, dirs, files in os.walk(input_filepath):\n",
    "    tissue = os.path.basename(subdir)\n",
    "    file_idx = 0\n",
    "    print('merging and csv...', tissue)\n",
    "    \n",
    "    \n",
    "    #DEBUG\n",
    "    if tissue!='H9_D28':\n",
    "        continue\n",
    "#     merged_loop_df = pd.DataFrame()\n",
    "#     merged_anchor_df = pd.DataFrame()\n",
    "\n",
    "    # loop through tissue folder\n",
    "    for filename in sorted(files):\n",
    "\n",
    "        input_filepath = os.path.join(subdir, filename )# bedpe file\n",
    "        output_filepath_tissue = subdir\n",
    "\n",
    "        if filename.endswith(extension) :\n",
    "            print(input_filepath)\n",
    "            loop_df = read_bedpe_file(input_filepath)\n",
    "            loop_df = filter_through_tss(loop_df,prom_bed)\n",
    "            print('read loop_df',loop_df.shape)\n",
    "            if file_idx==0:\n",
    "                merged_loop_df = loop_df\n",
    "                file_idx+=1\n",
    "                print('start',merged_loop_df.shape)\n",
    "#                 merged_anchor_df = anchors_df\n",
    "            else:\n",
    "                print('merging')\n",
    "                merged_loop_df = pd.concat([merged_loop_df, loop_df],ignore_index=True)\n",
    "                merged_loop_df = merged_loop_df.groupby(['source', 'target']).sum()\n",
    "                merged_loop_df.reset_index(inplace=True)\n",
    "                file_idx+=1\n",
    "                print('merging done',merged_loop_df.shape)\n",
    "\n",
    "#                 merged_anchor_df = pd.concat([merged_anchor_df, anchors_df],ignore_index=True)\n",
    "#                 merged_anchor_df.drop_duplicates(subset=['chr','start', 'end'],inplace=True)\n",
    "#                 merged_anchor_df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    \n",
    "    # end loop through tissue folder\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "anchor_width = 5000\n",
    "valid_chr = [str(x) for x in list(range(1,22))]+['X','Y']\n",
    "with open('../data/raw/hichip/H9_D0/H9-B1.filt.intra.loop_counts.bedpe', 'r') as f:\n",
    "    results = defaultdict(int)\n",
    "#     result_idx=0\n",
    "    for idx, line in enumerate(f.readlines()):\n",
    "        #DEBUG\n",
    "#         if idx>100:\n",
    "#             break\n",
    "        if (idx % 500000)==0:\n",
    "            print(idx)\n",
    "        chr_x, start_x , stop_x,  chr_y , start_y , stop_y , etc , count  = line.strip().split(' ')\n",
    "        \n",
    "        if chr_x not in valid_chr:\n",
    "            continue\n",
    "        if chr_y not in valid_chr:\n",
    "            continue\n",
    "        \n",
    "        #rounding to anchor width\n",
    "        chr_x = 'chr'+chr_x\n",
    "        start_x = round(int(start_x)/anchor_width)*anchor_width\n",
    "        stop_x = max(start_x+anchor_width,round(int(stop_x)/anchor_width)*anchor_width)\n",
    "        chr_y = 'chr'+chr_y\n",
    "        start_y = round(int(start_y)/anchor_width)*anchor_width\n",
    "        stop_y = max(start_y+anchor_width,round(int(stop_y)/anchor_width)*anchor_width)\n",
    "\n",
    "        #partitioning to anchor width (deal with large fragments)\n",
    "        anchors_x=[]\n",
    "        for x in range(start_x, stop_x,anchor_width):\n",
    "            anchors_x.append(chr_x+'_' + str(x) +\"_\"+str(x+anchor_width))\n",
    "        anchors_y=[]\n",
    "        for x in range(start_y, stop_y,anchor_width):\n",
    "            anchors_y.append(chr_y+'_' + str(x) +\"_\"+str(x+anchor_width))\n",
    "        \n",
    "        for source in anchors_x:\n",
    "            for target in anchors_y:\n",
    "                results[(source,target)] += int(count)\n",
    "                results[(target,source)] += int(count)\n",
    "            \n",
    "loop_df = pd.concat([pd.DataFrame(results.keys()),pd.DataFrame(results.values())],axis=1)\n",
    "loop_df.columns=['source','target','count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
